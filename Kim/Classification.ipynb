{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e77a53d-bc85-4c1c-b4bb-84056a4620cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b82ab9-ced4-45b6-9638-1f36f5385122",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.read_csv(\"./FinalDatasets/TotalDataset_Engineered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5ffc00c-85a7-4002-b53f-98727a419166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date first seen</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Proto</th>\n",
       "      <th>Src IP Addr</th>\n",
       "      <th>Src Pt</th>\n",
       "      <th>Dst IP Addr</th>\n",
       "      <th>Dst Pt</th>\n",
       "      <th>Packets</th>\n",
       "      <th>Bytes</th>\n",
       "      <th>...</th>\n",
       "      <th>S</th>\n",
       "      <th>F</th>\n",
       "      <th>class</th>\n",
       "      <th>attackType</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>days</th>\n",
       "      <th>hours</th>\n",
       "      <th>minutes</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-03-15 00:01:16.632</td>\n",
       "      <td>0.000</td>\n",
       "      <td>TCP</td>\n",
       "      <td>192.168.100.5</td>\n",
       "      <td>445</td>\n",
       "      <td>192.168.220.16</td>\n",
       "      <td>58844.0</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-03-15 00:01:16.552</td>\n",
       "      <td>0.000</td>\n",
       "      <td>TCP</td>\n",
       "      <td>192.168.100.5</td>\n",
       "      <td>445</td>\n",
       "      <td>192.168.220.15</td>\n",
       "      <td>48888.0</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-15 00:01:16.551</td>\n",
       "      <td>0.004</td>\n",
       "      <td>TCP</td>\n",
       "      <td>192.168.220.15</td>\n",
       "      <td>48888</td>\n",
       "      <td>192.168.100.5</td>\n",
       "      <td>445.0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-03-15 00:01:16.631</td>\n",
       "      <td>0.004</td>\n",
       "      <td>TCP</td>\n",
       "      <td>192.168.220.16</td>\n",
       "      <td>58844</td>\n",
       "      <td>192.168.100.5</td>\n",
       "      <td>445.0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2017-03-15 00:01:17.432</td>\n",
       "      <td>0.000</td>\n",
       "      <td>TCP</td>\n",
       "      <td>192.168.220.9</td>\n",
       "      <td>37884</td>\n",
       "      <td>192.168.100.5</td>\n",
       "      <td>445.0</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          Date first seen  Duration Proto     Src IP Addr  \\\n",
       "0           0  2017-03-15 00:01:16.632     0.000   TCP   192.168.100.5   \n",
       "1           1  2017-03-15 00:01:16.552     0.000   TCP   192.168.100.5   \n",
       "2           2  2017-03-15 00:01:16.551     0.004   TCP  192.168.220.15   \n",
       "3           3  2017-03-15 00:01:16.631     0.004   TCP  192.168.220.16   \n",
       "4           4  2017-03-15 00:01:17.432     0.000   TCP   192.168.220.9   \n",
       "\n",
       "   Src Pt     Dst IP Addr   Dst Pt  Packets  Bytes  ...  S  F   class  \\\n",
       "0     445  192.168.220.16  58844.0        1    108  ...  0  0  normal   \n",
       "1     445  192.168.220.15  48888.0        1    108  ...  0  0  normal   \n",
       "2   48888   192.168.100.5    445.0        2    174  ...  0  0  normal   \n",
       "3   58844   192.168.100.5    445.0        2    174  ...  0  0  normal   \n",
       "4   37884   192.168.100.5    445.0        1     66  ...  0  0  normal   \n",
       "\n",
       "   attackType  year  month days hours  minutes  seconds  \n",
       "0        none  2017      3   15     0        1   16.632  \n",
       "1        none  2017      3   15     0        1   16.552  \n",
       "2        none  2017      3   15     0        1   16.551  \n",
       "3        none  2017      3   15     0        1   16.631  \n",
       "4        none  2017      3   15     0        1   17.432  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1b57e82-db7e-4f8b-ab62-2522abd0f996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39643009 entries, 0 to 39643008\n",
      "Data columns (total 24 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   Unnamed: 0       int64  \n",
      " 1   Date first seen  object \n",
      " 2   Duration         float64\n",
      " 3   Proto            object \n",
      " 4   Src IP Addr      object \n",
      " 5   Src Pt           int64  \n",
      " 6   Dst IP Addr      object \n",
      " 7   Dst Pt           float64\n",
      " 8   Packets          int64  \n",
      " 9   Bytes            int64  \n",
      " 10  U                int64  \n",
      " 11  A                int64  \n",
      " 12  P                int64  \n",
      " 13  R                int64  \n",
      " 14  S                int64  \n",
      " 15  F                int64  \n",
      " 16  class            object \n",
      " 17  attackType       object \n",
      " 18  year             int64  \n",
      " 19  month            int64  \n",
      " 20  days             int64  \n",
      " 21  hours            int64  \n",
      " 22  minutes          int64  \n",
      " 23  seconds          float64\n",
      "dtypes: float64(3), int64(15), object(6)\n",
      "memory usage: 7.1+ GB\n"
     ]
    }
   ],
   "source": [
    "total_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "721eb906-6853-4744-94dd-be65d78eda56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Proto', 'Src IP Addr', 'Dst IP Addr']:\n",
    "    total_data[col] = total_data[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a65b2-c432-48af-b6d1-bfb206f6f5bd",
   "metadata": {},
   "source": [
    "#### One concern I have with some of these features is that the featuers with IP Addresses I believe should be removed. \n",
    "#### Because what happens if we test on new data and that data contains an IP address that the model has never seen before and we are feeding the IP Address as a categorical column. \n",
    "#### So either we modify the data/model to take in the IP Address as a varying non-categorical value OR we drop the IP Addresses feature totally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af3a07-858b-4944-82a7-93b34463fdb2",
   "metadata": {},
   "source": [
    "# Prepping for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a03786d8-4fe3-418c-87e2-04ec0819d165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Duration', 'Src Pt', 'Dst Pt', 'Packets', 'Bytes', 'U', 'A', 'P', 'R', 'S', 'F', 'year', 'month', 'days', 'hours', 'minutes', 'seconds']\n"
     ]
    }
   ],
   "source": [
    "features = list(total_data.columns)\n",
    "features.remove(\"Unnamed: 0\")\n",
    "features.remove(\"Date first seen\")\n",
    "features.remove(\"class\")\n",
    "features.remove(\"attackType\")\n",
    "\n",
    "features.remove('Proto')\n",
    "features.remove('Src IP Addr')\n",
    "features.remove('Dst IP Addr')\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c01ff01a-f974-4351-a308-22dc490ffb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Label Encoding our target variable column\n",
    "le = LabelEncoder()\n",
    "total_data['attackType'] = le.fit_transform(total_data['attackType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "044b0fc1-505d-4fc6-8a08-d92e6740439f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blasterWorm': 0, 'bruteForce': 1, 'dos': 2, 'fragmentation': 3, 'httpFlood': 4, 'icmpFlood': 5, 'landAttack': 6, 'none': 7, 'pingScan': 8, 'portScan': 9, 'reaperWorm': 10, 'redWorm': 11, 'scanning': 12, 'smurf': 13, 'spam': 14, 'synFlood': 15, 'udpFlood': 16}\n"
     ]
    }
   ],
   "source": [
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94820df9-1f3a-40e5-9cec-5e713a9b3c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"attackType\" # This is going to be a multiclass classification task "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7111df-180d-4735-984e-822e6432155d",
   "metadata": {},
   "source": [
    "#### Since I will be using CatBoostClassifier first, we won't need to undergo any feature normalization of sorts as it is a tree based model.\n",
    "#### However, there are some articles and papers out there mentioning since this is a gradient boosting model, we would still need to normalize data. For now, I will just proceed on but would be a good attempt to try and normalize the data in the future and observe if there are any meaningful changes to the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c29c0f-7156-4cc9-9786-1e1c798f4577",
   "metadata": {},
   "source": [
    "# Splitting data up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b895c84c-ac77-45ca-82f1-29beb12e5cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Split():\n",
    "    \n",
    "    def __init__(self, num = 5):  # num refers to the number of datasets you wanna split the original total dataset into\n",
    "        self.total_data = total_data\n",
    "        self.target = le.classes_.tolist()\n",
    "        self._0 = []\n",
    "        self._1 = []\n",
    "        self._2 = []\n",
    "        self._3 = []\n",
    "        self._4 = []\n",
    "        self._5 = []\n",
    "        self._6 = []\n",
    "        self._7 = []\n",
    "        self._8 = []\n",
    "        self._9 = []\n",
    "        self._10 = []\n",
    "        self._11 = []\n",
    "        self._12 = []\n",
    "        self._13 = []\n",
    "        self._14 = []\n",
    "        self._15 = []\n",
    "        self._16 = []\n",
    "        self.cv = num\n",
    "\n",
    "    def generate(self):\n",
    "        self._split()\n",
    "\n",
    "        res = []\n",
    "        \n",
    "        for i in tqdm(range(self.cv)):\n",
    "            if i != self.cv-1:\n",
    "                tmp = self._0[i*(len(self._0)//self.cv):(i+1)*(len(self._0)//self.cv)] + self._1[i*(len(self._1)//self.cv):(i+1)*(len(self._1)//self.cv)] + self._2[i*(len(self._2)//self.cv):(i+1)*(len(self._2)//self.cv)] + self._3[i*(len(self._3)//self.cv):(i+1)*(len(self._3)//self.cv)] + self._4[i*(len(self._4)//self.cv):(i+1)*(len(self._4)//self.cv)] + self._5[i*(len(self._5)//self.cv):(i+1)*(len(self._5)//self.cv)] + self._6[i*(len(self._6)//self.cv):(i+1)*(len(self._6)//self.cv)] + self._7[i*(len(self._7)//self.cv):(i+1)*(len(self._7)//self.cv)] + self._8[i*(len(self._8)//self.cv):(i+1)*(len(self._8)//self.cv)] + self._9[i*(len(self._9)//self.cv):(i+1)*(len(self._9)//self.cv)] + self._10[i*(len(self._10)//self.cv):(i+1)*(len(self._10)//self.cv)] + self._11[i*(len(self._11)//self.cv):(i+1)*(len(self._11)//self.cv)] + self._12[i*(len(self._12)//self.cv):(i+1)*(len(self._12)//self.cv)] + self._13[i*(len(self._13)//self.cv):(i+1)*(len(self._13)//self.cv)] + self._14[i*(len(self._14)//self.cv):(i+1)*(len(self._14)//self.cv)] + self._15[i*(len(self._15)//self.cv):(i+1)*(len(self._15)//self.cv)] + self._16[i*(len(self._16)//self.cv):(i+1)*(len(self._16)//self.cv)]\n",
    "            elif i == self.cv-1:\n",
    "                tmp = self._0[i*(len(self._0)//self.cv):-1] + self._1[i*(len(self._1)//self.cv):-1] + self._2[i*(len(self._2)//self.cv):-1] + self._3[i*(len(self._3)//self.cv):-1] + self._4[i*(len(self._4)//self.cv):-1] + self._5[i*(len(self._5)//self.cv):-1] + self._6[i*(len(self._6)//self.cv):-1] + self._7[i*(len(self._7)//self.cv):-1] + self._8[i*(len(self._8)//self.cv):-1] + self._9[i*(len(self._9)//self.cv):-1] + self._10[i*(len(self._10)//self.cv):-1] + self._11[i*(len(self._11)//self.cv):-1] + self._12[i*(len(self._12)//self.cv):-1] + self._13[i*(len(self._13)//self.cv):-1] + self._14[i*(len(self._14)//self.cv):-1] + self._15[i*(len(self._15)//self.cv):-1] + self._16[i*(len(self._16)//self.cv):-1]\n",
    "            res.append(tmp)\n",
    "\n",
    "        return res # Returns arrays of indices\n",
    "        \n",
    "    def _split(self):\n",
    "        length = len(self.total_data)\n",
    "        print(\"Splitting...\")\n",
    "        for i in tqdm(range(length)):\n",
    "            type = self.total_data.iloc[i].attackType\n",
    "            match type:\n",
    "                case 0:\n",
    "                    self._0.append(i)\n",
    "                case 1:\n",
    "                    self._1.append(i)\n",
    "                case 2:\n",
    "                    self._2.append(i)\n",
    "                case 3:\n",
    "                    self._3.append(i)\n",
    "                case 4:\n",
    "                    self._4.append(i)\n",
    "                case 5: \n",
    "                    self._5.append(i)\n",
    "                case 6:\n",
    "                    self._6.append(i)\n",
    "                case 7:\n",
    "                    self._7.append(i)\n",
    "                case 8:\n",
    "                    self._8.append(i)\n",
    "                case 9:\n",
    "                    self._9.append(i)\n",
    "                case 10:\n",
    "                    self._10.append(i)\n",
    "                case 11:\n",
    "                    self._11.append(i)\n",
    "                case 12:\n",
    "                    self._12.append(i)\n",
    "                case 13:\n",
    "                    self._13.append(i)\n",
    "                case 14:\n",
    "                    self._14.append(i)\n",
    "                case 15:\n",
    "                    self._15.append(i)\n",
    "                case 16:\n",
    "                    self._16.append(i)\n",
    "\n",
    "        print(\"Splitting done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaed510e-8e9d-43fb-82f2-300f3e8184b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39643009/39643009 [20:15<00:00, 32610.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.34it/s]\n"
     ]
    }
   ],
   "source": [
    "subset_count = 10\n",
    "split = Split(num = subset_count) # num refers to the number of datasets you wanna split the original total dataset into\n",
    "split_data = split.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e4be105-0818-4c8d-95b9-132be70fba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_subset = 0\n",
    "\n",
    "X = total_data.iloc[split_data[select_subset]][features]\n",
    "y = total_data.iloc[split_data[select_subset]][target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c358938-bb58-44f8-ac8d-ead2cdcab6e7",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4ab0f6e-a7f7-45b5-bd8f-2bbde84d6813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Take the models from here\n",
    "\n",
    "xgb = XGBClassifier(objective='multi:softprob',\n",
    "                   enable_categorical=True)\n",
    "\n",
    "cat = CatBoostClassifier(loss_function='MultiClass', # MultiClass, MultiClassOneVsAll\n",
    "                         eval_metric =  'Accuracy', # AUC\n",
    "                         verbose=10,\n",
    "                         depth = 5,\n",
    "                         early_stopping_rounds=10,\n",
    "                         # cat_features=[1, 2, 4]\n",
    "                        )\n",
    "\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "563667d1-8f62-40da-8917-eab4618809a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold-1\n",
      "----------------------\n",
      "Training...\n",
      "----------------------\n",
      "Learning rate set to 0.126868\n",
      "0:\tlearn: 0.9901212\ttest: 0.9908962\tbest: 0.9908962 (0)\ttotal: 3.26s\tremaining: 54m 13s\n",
      "10:\tlearn: 0.9954648\ttest: 0.9945690\tbest: 0.9945791 (9)\ttotal: 24.4s\tremaining: 36m 33s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.9945791118\n",
      "bestIteration = 9\n",
      "\n",
      "Shrink model to first 10 iterations.\n",
      "Training done!\n",
      "----------------------\n",
      "Accuracy: 99.46%\n",
      "Time taken: 43s\n",
      "----------------------\n",
      "\n",
      "Fold-2\n",
      "----------------------\n",
      "Training...\n",
      "----------------------\n",
      "Learning rate set to 0.126868\n",
      "0:\tlearn: 0.9901786\ttest: 0.9906667\tbest: 0.9906667 (0)\ttotal: 2.49s\tremaining: 41m 29s\n",
      "10:\tlearn: 0.9955402\ttest: 0.5624607\tbest: 0.9906667 (0)\ttotal: 18.6s\tremaining: 27m 52s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.9906666885\n",
      "bestIteration = 0\n",
      "\n",
      "Shrink model to first 1 iterations.\n",
      "Training done!\n",
      "----------------------\n",
      "Accuracy: 99.07%\n",
      "Time taken: 21s\n",
      "----------------------\n",
      "\n",
      "Fold-3\n",
      "----------------------\n",
      "Training...\n",
      "----------------------\n",
      "Learning rate set to 0.126868\n",
      "0:\tlearn: 0.9902650\ttest: 0.9903211\tbest: 0.9903211 (0)\ttotal: 2.13s\tremaining: 35m 29s\n",
      "10:\tlearn: 0.9952186\ttest: 0.9955894\tbest: 0.9955894 (4)\ttotal: 16.8s\tremaining: 25m 7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.9955893797\n",
      "bestIteration = 4\n",
      "\n",
      "Shrink model to first 5 iterations.\n",
      "Training done!\n",
      "----------------------\n",
      "Accuracy: 99.56%\n",
      "Time taken: 24s\n",
      "----------------------\n",
      "\n",
      "Fold-4\n",
      "----------------------\n",
      "Training...\n",
      "----------------------\n",
      "Learning rate set to 0.126868\n",
      "0:\tlearn: 0.9903996\ttest: 0.9897233\tbest: 0.9897233 (0)\ttotal: 1.67s\tremaining: 27m 44s\n",
      "10:\tlearn: 0.9931476\ttest: 0.9934414\tbest: 0.9934414 (4)\ttotal: 15.9s\tremaining: 23m 53s\n",
      "20:\tlearn: 0.9960147\ttest: 0.9959072\tbest: 0.9959072 (14)\ttotal: 29.3s\tremaining: 22m 47s\n",
      "30:\tlearn: 0.9969585\ttest: 0.9968279\tbest: 0.9969591 (25)\ttotal: 43.5s\tremaining: 22m 40s\n",
      "40:\tlearn: 0.9970114\ttest: 0.9969200\tbest: 0.9970398 (33)\ttotal: 57s\tremaining: 22m 14s\n",
      "50:\tlearn: 0.9978571\ttest: 0.6929690\tbest: 0.9971723 (47)\ttotal: 1m 12s\tremaining: 22m 21s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.9971722553\n",
      "bestIteration = 47\n",
      "\n",
      "Shrink model to first 48 iterations.\n",
      "Training done!\n",
      "----------------------\n",
      "Accuracy: 99.72%\n",
      "Time taken: 88s\n",
      "----------------------\n",
      "\n",
      "Fold-5\n",
      "----------------------\n",
      "Training...\n",
      "----------------------\n",
      "Learning rate set to 0.126868\n",
      "0:\tlearn: 0.9903939\ttest: 0.9897460\tbest: 0.9897460 (0)\ttotal: 1.77s\tremaining: 29m 32s\n",
      "10:\tlearn: 0.9931738\ttest: 0.9938400\tbest: 0.9938400 (8)\ttotal: 17.1s\tremaining: 25m 36s\n",
      "20:\tlearn: 0.9959444\ttest: 0.9961998\tbest: 0.9961998 (17)\ttotal: 30.5s\tremaining: 23m 43s\n",
      "30:\tlearn: 0.9969787\ttest: 0.9970386\tbest: 0.9970386 (27)\ttotal: 46.6s\tremaining: 24m 16s\n",
      "40:\tlearn: 0.9972334\ttest: 0.9973413\tbest: 0.9973413 (39)\ttotal: 1m 1s\tremaining: 23m 58s\n",
      "50:\tlearn: 0.9973009\ttest: 0.9974245\tbest: 0.9974245 (50)\ttotal: 1m 16s\tremaining: 23m 37s\n",
      "60:\tlearn: 0.9979322\ttest: 0.9980350\tbest: 0.9980350 (52)\ttotal: 1m 35s\tremaining: 24m 27s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.9980349571\n",
      "bestIteration = 52\n",
      "\n",
      "Shrink model to first 53 iterations.\n",
      "Training done!\n",
      "----------------------\n",
      "Accuracy: 99.80%\n",
      "Time taken: 100s\n",
      "----------------------\n",
      "----------------------\n",
      "Average accuracy: 99.52%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(X, y)\n",
    "acc = []\n",
    "models = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    start_time = time.time()\n",
    "    print(f\"\\nFold-{i+1}\")\n",
    "    print(\"----------------------\")\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Paste models here\n",
    "    model = CatBoostClassifier(loss_function='MultiClass', # MultiClass, MultiClassOneVsAll\n",
    "                         eval_metric =  'Accuracy', # AUC\n",
    "                         verbose=10,\n",
    "                         depth = 5,\n",
    "                         early_stopping_rounds=10,\n",
    "                         # cat_features=[1, 2, 4]\n",
    "                        )\n",
    "\n",
    "    # Train\n",
    "    print(\"Training...\")\n",
    "    print(\"----------------------\")\n",
    "    model.fit(X_train, y_train, eval_set=(X_test, y_test))\n",
    "    models.append(model)\n",
    "    print(\"Training done!\")\n",
    "    print(\"----------------------\")\n",
    "\n",
    "    # Predict\n",
    "    pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    acc.append(accuracy)\n",
    "    # auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1], multi_class='ovr')\n",
    "\n",
    "    # Printing\n",
    "    print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
    "    # print(\"AUC: {:.2f}\".format(auc))\n",
    "    print(\"Time taken: {:.0f}s\".format(time.time()-start_time))\n",
    "    print(\"----------------------\")\n",
    "\n",
    "print(\"----------------------\")\n",
    "print(\"Average accuracy: {:.2f}%\".format(np.mean(acc)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862fbe8c-172d-4171-ba89-93367525c61c",
   "metadata": {},
   "source": [
    "# Testing on a different subset of dataset (never seen before by the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "64e4e05f-aa55-47a1-af83-a34ce79ef395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:59<00:00,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy over the other subsets of the total data: 39.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "orig = [i for i in range(10)]\n",
    "orig.remove(0)\n",
    "total_acc = []\n",
    "\n",
    "for i in tqdm(orig):\n",
    "    X_new = total_data.iloc[split_data[i]][features]\n",
    "    y_new = total_data.iloc[split_data[i]][target]\n",
    "    acc = []\n",
    "    \n",
    "    for model in models:\n",
    "        pred_new = model.predict(X_new)\n",
    "        accuracy_new = accuracy_score(y_new, pred_new)\n",
    "        acc.append(accuracy_new)\n",
    "\n",
    "    total_acc.append(np.mean(acc))\n",
    "\n",
    "print(\"Total accuracy over the other subsets of the total data: {:.2f}%\".format(np.mean(total_acc)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
