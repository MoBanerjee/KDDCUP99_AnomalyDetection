{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f6a63c-e914-4d1d-86c3-1cca3dfd1382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Import\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacc0d02-6dbe-43ba-bc8e-bc152b5f62f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Date Engineering\n",
    "\n",
    "total_data = pd.read_csv(\"./FinalDatasets/TotalDataset_Engineered.csv\")\n",
    "for col in ['Proto', 'Src IP Addr', 'Dst IP Addr']:\n",
    "    total_data[col] = total_data[col].astype('category')\n",
    "\n",
    "# Removing redundant features\n",
    "\n",
    "features = list(total_data.columns)\n",
    "features.remove(\"Unnamed: 0\")\n",
    "features.remove(\"Date first seen\")\n",
    "features.remove(\"class\")\n",
    "features.remove(\"attackType\")\n",
    "\n",
    "# Dropping these columns for now\n",
    "features.remove('Proto')\n",
    "features.remove('Src IP Addr')\n",
    "features.remove('Dst IP Addr')\n",
    "\n",
    "target = 'class'\n",
    "\n",
    "# Label Encoding our target variable column\n",
    "le = LabelEncoder()\n",
    "total_data[target] = le.fit_transform(total_data[target])\n",
    "\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "# 1 - normal & 0 - attack\n",
    "for i in tqdm(range(len(total_data))):\n",
    "    if (total_data.iloc[i]['class']) != 1:\n",
    "        total_data.at[i, 'class'] = 0\n",
    "\n",
    "target = \"attackType\" \n",
    "# Label Encoding our target variable column\n",
    "le = LabelEncoder()\n",
    "total_data[target] = le.fit_transform(total_data[target])\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "total_data.to_csv(\"./FinalDatasets/FinalDataset.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa15fcc-f494-4186-9c69-13d0c0a1c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.read_csv(\"./FinalDatasets/FinalDataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa71864-a833-43ac-ba98-dbe69211fba1",
   "metadata": {},
   "source": [
    "# Pipelining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b10ab1-38d6-4594-917a-a72daa40e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel:\n",
    "    def __init__(self, \n",
    "                data, \n",
    "                model_1, \n",
    "                model_2,\n",
    "                features = ['Duration', 'Src Pt', 'Dst Pt', 'Packets', 'Bytes', 'U', 'A', 'P', 'R', 'S', 'F', 'year', 'month', 'days', 'hours', 'minutes', 'seconds']               \n",
    "                ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pandas DataFrame\n",
    "            Data containing rows of data you wish to predict on\n",
    "        model_1 : filepath\n",
    "            Model predicting binary \n",
    "        model_2 : filepath\n",
    "            Model predicting multiclass\n",
    "        features: list\n",
    "            List of the feature columns we wish to use\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.model_1 = pickle.load(open(model_1, \"rb\"))\n",
    "        self.model_2 = pickle.load(open(model_2, \"rb\"))\n",
    "\n",
    "        # Feature columns\n",
    "        self.features = features\n",
    "        for feature in self.features:\n",
    "            if feature in self.data.columns:\n",
    "                continue\n",
    "            else:\n",
    "                raise Exception(\"Check feature list again\")\n",
    "            \n",
    "        \n",
    "    def _stage_1_predict(self): # {'anamoly': 0, 'normal': 1}\n",
    "        try:\n",
    "            pred = self.model_1.predict(self.data[self.features])\n",
    "            return pred\n",
    "        except:\n",
    "            print(\"Error in stage 1 prediction\")\n",
    "            return 0\n",
    "\n",
    "    def _stage_2_predict(self):\n",
    "        try:\n",
    "            pred = self.model_2.predict(self.data[self.features])\n",
    "            return pred\n",
    "        except:\n",
    "            print(\"Error in stage 2 prediction\")\n",
    "            return 0\n",
    "\n",
    "    def _obtain_final_res(self):\n",
    "        res = []\n",
    "        for i in range(len(self.data)):\n",
    "            if self.data['stage_1'].iloc[i] == 1:\n",
    "                res.append(7) # According to my label encoder mapping, 7 is mapped to None - please exercise personal discretion\n",
    "            else: # When anamoly is detected\n",
    "                var = self.data['stage_2'].iloc[i]\n",
    "                res.append(var)\n",
    "        return res\n",
    "\n",
    "    def run(self):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Stage 1 prediction\n",
    "        stage_1_pred = self._stage_1_predict()\n",
    "        self.data['stage_1'] = stage_1_pred\n",
    "\n",
    "        # Stage 2 prediction\n",
    "        stage_2_pred = self._stage_2_predict()\n",
    "        self.data['stage_2'] = stage_2_pred\n",
    "\n",
    "        # Obtaining final pred\n",
    "        final_res = self._obtain_final_res()\n",
    "        self.data['final pred'] = final_res\n",
    "        \n",
    "        print(\"Program took\", (time.time() - start_time)/60 , \"minutes to run\")\n",
    "        \n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a6a77-804f-412d-8ba1-d156fb652af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = FullModel(total_data, 'binary_xgb_1.pkl', 'multiclass_xgb_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778ca7ee-9488-41d8-9a52-60abbbe07ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = algo.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34803b3-0e8e-4baf-b952-c4d552757c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf2f34-6ad1-45f0-9275-70f3ee8a67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_accuracy = len(new_data[new_data['attackType'] == new_data['final pred']])/len(new_data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005303cf-b9a8-4ef7-aac0-638ccaefeec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a01aa30e7cb9fc7776677534e11c9ab1eed0bfffb3501a39ef7b976f9557b493"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
